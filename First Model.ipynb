{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principes\n",
    "===\n",
    "\n",
    "- multi-target (using all `resp`)\n",
    "- weight also is a var\n",
    "- features were generated\n",
    "- using Time Cross Validation\n",
    "- using Neptune to log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import create_encoder, create_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from neptunecontrib.monitoring.keras import NeptuneMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshhold(array, value):\n",
    "    return np.median(array) + np.std(array)*value#- np.std(array)*0.35\n",
    "\n",
    "\n",
    "def load_train_data(path_to_train_csv):\n",
    "    # Load 50 rows to understand types of cols\n",
    "    train_csv = pd.read_csv(path_to_train_csv, nrows=50) \n",
    "    # Finding float cols\n",
    "    float_cols = [c for c in train_csv if train_csv[c].dtype == \"float64\"]\n",
    "    # Float64 to Float16\n",
    "    types = {c: 'float32' for c in float_cols}\n",
    "    # Loading all rows\n",
    "    train_csv = pd.read_csv(path_to_train_csv, engine='c', dtype=types) \n",
    "    \n",
    "    \n",
    "    resp = np.where(train_csv['resp'] > get_threshhold(train_csv['resp'].values, 0),    1, 0)\n",
    "    resp_1 = np.where(train_csv['resp_1'] > get_threshhold(train_csv['resp_1'].values, 0.25),     1, 0)\n",
    "    resp_2 = np.where(train_csv['resp_2'] > get_threshhold(train_csv['resp_2'].values, -0.25),    1, 0)\n",
    "    resp_3 = np.where(train_csv['resp_3'] > get_threshhold(train_csv['resp_3'].values, -0.35),           1, 0)\n",
    "    resp_4 = np.where(train_csv['resp_4'] > get_threshhold(train_csv['resp_4'].values, 0),           1, 0)\n",
    "    \n",
    "\n",
    "    train_csv['resp'] = resp_1\n",
    "    train_csv['resp_1'] = resp_1\n",
    "    train_csv['resp_2'] = resp_1\n",
    "    train_csv['resp_3'] = resp_1\n",
    "    train_csv['resp_4'] = resp_1\n",
    "    \n",
    "    \n",
    "    return train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = load_train_data('train_processed_sc.csv')\n",
    "train_bool = True\n",
    "evalution_bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multitarget     # threshold- is tunable paramer, if threshold>0 - drops false postive rate\n",
    "def spltter(train_csv, threshold=0):\n",
    "#     test_csv = train_csv.sample(frac=0.2)\n",
    "#     train_csv.drop(index=test_csv.index, inplace=True)\n",
    "    \n",
    "    dates = train_csv['date'].unique()\n",
    "    test_dates = np.array([380, 168,  33,  94, 309, 348, 488, 476, 154,  37, 195,  30, 332,\n",
    "       365, 363, 256, 320, 227, 219, 153, 424, 236,  22, 329, 165, 128,\n",
    "       352, 187, 158,  45, 423, 150, 331,  64, 263, 296,  69, 144,  15,\n",
    "       250, 426, 114, 223, 360, 269, 177, 208, 326, 429, 499, 214, 463,\n",
    "       438, 178,  40, 121, 284, 258,   8, 143, 290, 321, 496, 215, 477,\n",
    "       382,  58,  31,  54, 337, 497,  83,  39, 410, 455]) # #) #np.random.choice(dates, size=int(dates.size*0.15), replace=False, p=None)\n",
    "    train_dates = np.setdiff1d(dates, test_dates)\n",
    "    \n",
    "    test_csv = train_csv[train_csv['date'].isin(test_dates)]\n",
    "    train_csv = train_csv[train_csv['date'].isin(train_dates)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    features = [c for c in train_csv.columns if 'feature' in c] + ['weight']\n",
    "    resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4'] \n",
    "\n",
    "    X_train = train_csv[features].values\n",
    "    y_train = train_csv[resp_cols].values #np.stack([(train_csv[c] > 0).astype('int') for c in resp_cols]).T \n",
    "    \n",
    "    X_test = test_csv[features].values\n",
    "    y_test = test_csv[resp_cols].values# np.stack([(test_csv[c] > 0).astype('int') for c in resp_cols]).T \n",
    "\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, test_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2010418, 131)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, test_dates = spltter(train_csv)\n",
    "del train_csv\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([380, 168,  33,  94, 309, 348, 488, 476, 154,  37, 195,  30, 332,\n",
       "       365, 363, 256, 320, 227, 219, 153, 424, 236,  22, 329, 165, 128,\n",
       "       352, 187, 158,  45, 423, 150, 331,  64, 263, 296,  69, 144,  15,\n",
       "       250, 426, 114, 223, 360, 269, 177, 208, 326, 429, 499, 214, 463,\n",
       "       438, 178,  40, 121, 284, 258,   8, 143, 290, 321, 496, 215, 477,\n",
       "       382,  58,  31,  54, 337, 497,  83,  39, 410, 455])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "psutil is not installed. You will not be able to abort this experiment from the UI.\n",
      "psutil is not installed. Hardware metrics will not be collected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/kopinhruk/nn-market/e/NNMAR-36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Experiment(NNMAR-36)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neptune\n",
    "api_token = 'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiYzhlNGMzYzYtZGU4Yi00OGY4LThiZTYtYzc0M2Q1NGU5MTRjIn0='\n",
    "neptune.init(project_qualified_name='kopinhruk/nn-market',api_token=api_token)\n",
    "neptune.create_experiment('proc_thresh', description='+0 select thresh, 0.4 pred thresh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "526/526 [==============================] - 11s 13ms/step - loss: 0.9102 - decoded_loss: 0.3931 - label_output_loss: 0.5170 - val_loss: 0.6282 - val_decoded_loss: 0.1550 - val_label_output_loss: 0.4731\n",
      "Epoch 2/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.7143 - decoded_loss: 0.2233 - label_output_loss: 0.4911 - val_loss: 0.5991 - val_decoded_loss: 0.1266 - val_label_output_loss: 0.4725\n",
      "Epoch 3/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6983 - decoded_loss: 0.2080 - label_output_loss: 0.4903 - val_loss: 0.5678 - val_decoded_loss: 0.0947 - val_label_output_loss: 0.4731\n",
      "Epoch 4/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6913 - decoded_loss: 0.2020 - label_output_loss: 0.4892 - val_loss: 0.5581 - val_decoded_loss: 0.0864 - val_label_output_loss: 0.4717\n",
      "Epoch 5/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6912 - decoded_loss: 0.2016 - label_output_loss: 0.4895 - val_loss: 0.5590 - val_decoded_loss: 0.0868 - val_label_output_loss: 0.4722\n",
      "Epoch 6/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6872 - decoded_loss: 0.1976 - label_output_loss: 0.4896 - val_loss: 0.5516 - val_decoded_loss: 0.0807 - val_label_output_loss: 0.4709\n",
      "Epoch 7/1000\n",
      "526/526 [==============================] - 7s 12ms/step - loss: 0.6865 - decoded_loss: 0.1975 - label_output_loss: 0.4890 - val_loss: 0.5485 - val_decoded_loss: 0.0777 - val_label_output_loss: 0.4708\n",
      "Epoch 8/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6854 - decoded_loss: 0.1963 - label_output_loss: 0.4891 - val_loss: 0.5492 - val_decoded_loss: 0.0778 - val_label_output_loss: 0.4715\n",
      "Epoch 9/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6859 - decoded_loss: 0.1971 - label_output_loss: 0.4888 - val_loss: 0.5459 - val_decoded_loss: 0.0749 - val_label_output_loss: 0.4710\n",
      "Epoch 10/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6828 - decoded_loss: 0.1948 - label_output_loss: 0.4880 - val_loss: 0.5468 - val_decoded_loss: 0.0754 - val_label_output_loss: 0.4714\n",
      "Epoch 11/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6843 - decoded_loss: 0.1954 - label_output_loss: 0.4890 - val_loss: 0.5470 - val_decoded_loss: 0.0762 - val_label_output_loss: 0.4709\n",
      "Epoch 12/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6825 - decoded_loss: 0.1941 - label_output_loss: 0.4884 - val_loss: 0.5436 - val_decoded_loss: 0.0727 - val_label_output_loss: 0.4709\n",
      "Epoch 13/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6837 - decoded_loss: 0.1954 - label_output_loss: 0.4884 - val_loss: 0.5432 - val_decoded_loss: 0.0726 - val_label_output_loss: 0.4706\n",
      "Epoch 14/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6837 - decoded_loss: 0.1942 - label_output_loss: 0.4895 - val_loss: 0.5436 - val_decoded_loss: 0.0718 - val_label_output_loss: 0.4717\n",
      "Epoch 15/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6827 - decoded_loss: 0.1943 - label_output_loss: 0.4884 - val_loss: 0.5499 - val_decoded_loss: 0.0793 - val_label_output_loss: 0.4706\n",
      "Epoch 16/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6816 - decoded_loss: 0.1933 - label_output_loss: 0.4883 - val_loss: 0.5408 - val_decoded_loss: 0.0700 - val_label_output_loss: 0.4708\n",
      "Epoch 17/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6791 - decoded_loss: 0.1911 - label_output_loss: 0.4881 - val_loss: 0.5443 - val_decoded_loss: 0.0742 - val_label_output_loss: 0.4701\n",
      "Epoch 18/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6802 - decoded_loss: 0.1917 - label_output_loss: 0.4885 - val_loss: 0.5424 - val_decoded_loss: 0.0714 - val_label_output_loss: 0.4710\n",
      "Epoch 19/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6802 - decoded_loss: 0.1926 - label_output_loss: 0.4877 - val_loss: 0.5421 - val_decoded_loss: 0.0713 - val_label_output_loss: 0.4708\n",
      "Epoch 20/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6809 - decoded_loss: 0.1921 - label_output_loss: 0.4888 - val_loss: 0.5455 - val_decoded_loss: 0.0750 - val_label_output_loss: 0.4704\n",
      "Epoch 21/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6811 - decoded_loss: 0.1923 - label_output_loss: 0.4888 - val_loss: 0.5465 - val_decoded_loss: 0.0759 - val_label_output_loss: 0.4707\n",
      "Epoch 22/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6793 - decoded_loss: 0.1913 - label_output_loss: 0.4880 - val_loss: 0.5437 - val_decoded_loss: 0.0730 - val_label_output_loss: 0.4707\n",
      "Epoch 23/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6796 - decoded_loss: 0.1911 - label_output_loss: 0.4885 - val_loss: 0.5411 - val_decoded_loss: 0.0711 - val_label_output_loss: 0.4700\n",
      "Epoch 24/1000\n",
      "526/526 [==============================] - 6s 12ms/step - loss: 0.6810 - decoded_loss: 0.1927 - label_output_loss: 0.4882 - val_loss: 0.5415 - val_decoded_loss: 0.0713 - val_label_output_loss: 0.4702\n",
      "Epoch 1/100\n",
      "  5/491 [..............................] - ETA: 1:08 - loss: 0.7665 - Precision: 0.2908 - Recall: 0.4880 - acc: 0.5923WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0149s vs `on_train_batch_end` time: 0.0848s). Check your callbacks.\n",
      "491/491 [==============================] - 12s 21ms/step - loss: 0.4993 - Precision: 0.4689 - Recall: 0.1007 - acc: 0.7569 - val_loss: 0.4950 - val_Precision: 0.5003 - val_Recall: 0.1270 - val_acc: 0.7563\n",
      "Epoch 2/100\n",
      "491/491 [==============================] - 9s 19ms/step - loss: 0.4802 - Precision: 0.5336 - Recall: 0.0834 - acc: 0.7657 - val_loss: 0.4920 - val_Precision: 0.5246 - val_Recall: 0.0882 - val_acc: 0.7583\n",
      "Epoch 3/100\n",
      "491/491 [==============================] - 9s 19ms/step - loss: 0.4784 - Precision: 0.5505 - Recall: 0.0835 - acc: 0.7672 - val_loss: 0.4909 - val_Precision: 0.5802 - val_Recall: 0.0487 - val_acc: 0.7596\n",
      "Epoch 4/100\n",
      "491/491 [==============================] - 9s 19ms/step - loss: 0.4777 - Precision: 0.5512 - Recall: 0.0879 - acc: 0.7674 - val_loss: 0.4908 - val_Precision: 0.5234 - val_Recall: 0.1071 - val_acc: 0.7586\n",
      "Epoch 5/100\n",
      "491/491 [==============================] - 9s 19ms/step - loss: 0.4768 - Precision: 0.5543 - Recall: 0.0938 - acc: 0.7676 - val_loss: 0.4893 - val_Precision: 0.5287 - val_Recall: 0.1025 - val_acc: 0.7590\n",
      "Epoch 6/100\n",
      "491/491 [==============================] - 9s 19ms/step - loss: 0.4759 - Precision: 0.5627 - Recall: 0.0979 - acc: 0.7685 - val_loss: 0.4893 - val_Precision: 0.5428 - val_Recall: 0.0826 - val_acc: 0.7595\n",
      "Epoch 7/100\n",
      "491/491 [==============================] - 9s 19ms/step - loss: 0.4750 - Precision: 0.5611 - Recall: 0.0994 - acc: 0.7684 - val_loss: 0.4897 - val_Precision: 0.5276 - val_Recall: 0.1122 - val_acc: 0.7592\n",
      "Epoch 8/100\n",
      "491/491 [==============================] - 9s 19ms/step - loss: 0.4748 - Precision: 0.5657 - Recall: 0.1090 - acc: 0.7690 - val_loss: 0.4880 - val_Precision: 0.5444 - val_Recall: 0.1000 - val_acc: 0.7603\n",
      "Epoch 9/100\n",
      "491/491 [==============================] - 10s 20ms/step - loss: 0.4734 - Precision: 0.5707 - Recall: 0.1148 - acc: 0.7698 - val_loss: 0.4898 - val_Precision: 0.5313 - val_Recall: 0.1079 - val_acc: 0.7594\n",
      "Epoch 10/100\n",
      "491/491 [==============================] - 10s 19ms/step - loss: 0.4724 - Precision: 0.5775 - Recall: 0.1166 - acc: 0.7707 - val_loss: 0.4900 - val_Precision: 0.5182 - val_Recall: 0.1208 - val_acc: 0.7584\n",
      "Epoch 11/100\n",
      "491/491 [==============================] - 10s 19ms/step - loss: 0.4721 - Precision: 0.5798 - Recall: 0.1195 - acc: 0.7710 - val_loss: 0.4905 - val_Precision: 0.5173 - val_Recall: 0.1236 - val_acc: 0.7583\n",
      "Epoch 12/100\n",
      "491/491 [==============================] - 10s 19ms/step - loss: 0.4706 - Precision: 0.5855 - Recall: 0.1273 - acc: 0.7721 - val_loss: 0.4912 - val_Precision: 0.5256 - val_Recall: 0.1048 - val_acc: 0.7588\n",
      "Epoch 13/100\n",
      "491/491 [==============================] - 10s 20ms/step - loss: 0.4700 - Precision: 0.5876 - Recall: 0.1338 - acc: 0.7723 - val_loss: 0.4910 - val_Precision: 0.5245 - val_Recall: 0.1142 - val_acc: 0.7589\n",
      "Epoch 14/100\n",
      "491/491 [==============================] - 10s 19ms/step - loss: 0.4680 - Precision: 0.5917 - Recall: 0.1362 - acc: 0.7738 - val_loss: 0.4932 - val_Precision: 0.5173 - val_Recall: 0.1135 - val_acc: 0.7582\n",
      "Epoch 15/100\n",
      "491/491 [==============================] - 10s 19ms/step - loss: 0.4679 - Precision: 0.5899 - Recall: 0.1399 - acc: 0.7734 - val_loss: 0.4928 - val_Precision: 0.5057 - val_Recall: 0.1427 - val_acc: 0.7571\n",
      "Epoch 16/100\n",
      "491/491 [==============================] - 10s 20ms/step - loss: 0.4661 - Precision: 0.5997 - Recall: 0.1453 - acc: 0.7750 - val_loss: 0.4932 - val_Precision: 0.5073 - val_Recall: 0.1287 - val_acc: 0.7572\n",
      "Epoch 17/100\n",
      "491/491 [==============================] - 10s 20ms/step - loss: 0.4635 - Precision: 0.6104 - Recall: 0.1527 - acc: 0.7765 - val_loss: 0.4948 - val_Precision: 0.5006 - val_Recall: 0.1307 - val_acc: 0.7564\n",
      "Epoch 18/100\n",
      "491/491 [==============================] - 10s 20ms/step - loss: 0.4624 - Precision: 0.6123 - Recall: 0.1610 - acc: 0.7772 - val_loss: 0.4958 - val_Precision: 0.4981 - val_Recall: 0.1376 - val_acc: 0.7560\n",
      "Epoch 19/100\n",
      "491/491 [==============================] - 10s 20ms/step - loss: 0.4611 - Precision: 0.6122 - Recall: 0.1669 - acc: 0.7778 - val_loss: 0.4964 - val_Precision: 0.4947 - val_Recall: 0.1481 - val_acc: 0.7555\n",
      "Epoch 20/100\n",
      "491/491 [==============================] - 10s 20ms/step - loss: 0.4614 - Precision: 0.6146 - Recall: 0.1699 - acc: 0.7777 - val_loss: 0.4965 - val_Precision: 0.4939 - val_Recall: 0.1425 - val_acc: 0.7554\n",
      "Epoch 21/100\n",
      "491/491 [==============================] - 10s 20ms/step - loss: 0.4609 - Precision: 0.6160 - Recall: 0.1697 - acc: 0.7783 - val_loss: 0.4971 - val_Precision: 0.4952 - val_Recall: 0.1380 - val_acc: 0.7557\n",
      "Epoch 22/100\n",
      "491/491 [==============================] - 10s 20ms/step - loss: 0.4604 - Precision: 0.6171 - Recall: 0.1684 - acc: 0.7788 - val_loss: 0.4975 - val_Precision: 0.4936 - val_Recall: 0.1423 - val_acc: 0.7554\n",
      "Epoch 23/100\n",
      "491/491 [==============================] - 10s 20ms/step - loss: 0.4604 - Precision: 0.6157 - Recall: 0.1720 - acc: 0.7788 - val_loss: 0.4978 - val_Precision: 0.4950 - val_Recall: 0.1389 - val_acc: 0.7556\n",
      "CPU times: user 9min 37s, sys: 33.1 s, total: 10min 10s\n",
      "Wall time: 6min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SEED = 123\n",
    "\n",
    "if train_bool:\n",
    "    X = np.concatenate((X_train, X_test))\n",
    "    y = np.concatenate((y_train, y_test))\n",
    "    set_all_seeds(SEED)\n",
    "\n",
    "    autoencoder, encoder = create_encoder(X.shape[-1],y.shape[-1],noise=0.1)\n",
    "    autoencoder.fit(X,(X,y),\n",
    "                    epochs=1000,\n",
    "                    batch_size=4096, \n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[\n",
    "                        EarlyStopping('val_loss',patience=8,restore_best_weights=True),\n",
    "                        #NeptuneMonitor()\n",
    "                    ])\n",
    "    #encoder.save_weights(f'./encoder_{SEED}.hdf5')\n",
    "    encoder.trainable=False\n",
    "\n",
    "    model = create_model(X.shape[-1],y.shape[-1],encoder)\n",
    "\n",
    "    del X\n",
    "    del y\n",
    "\n",
    "\n",
    "    model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=4096,\n",
    "              callbacks=[EarlyStopping('val_loss',patience=15,restore_best_weights=True),\n",
    "                         ReduceLROnPlateau('val_loss',patience=8),\n",
    "                         NeptuneMonitor(prefix='clsf_')\n",
    "                        ])\n",
    "\n",
    "    model.save_weights(f'./weights/model_{SEED}.hdf5')\n",
    "\n",
    "\n",
    "    del X_train, y_train#, X_test, y_test\n",
    "\n",
    "    # Finetune\n",
    "    #model.compile(Adam(hp.get('lr')/100),\n",
    "                #  loss=BinaryCrossentropy(label_smoothing=10*hp.get('label_smoothing'))) #trying something with ls here\n",
    "    #model.fit(X_test,y_test,epochs=3,batch_size=4096)\n",
    "    #model.save_weights(f'./model_{SEED}_{fold}_finetune.hdf5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalution / Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 1s 5ms/step\n",
      "Loading df\n"
     ]
    }
   ],
   "source": [
    "if evalution_bool:\n",
    "    # Creating model\n",
    "    _, encoder = create_encoder(X_test.shape[-1],y_test.shape[-1],noise=0.1)\n",
    "    encoder.trainable=False\n",
    "    model = create_model(X_test.shape[-1],y_test.shape[-1],encoder)\n",
    "    model.load_weights(f'./weights/model_{SEED}.hdf5')\n",
    "    \n",
    "    y_pred = model.predict(X_test, verbose=1, batch_size=4096) # n_samles x 5 (float)    \n",
    "        \n",
    "    print('Loading df')\n",
    "    test_df = pd.read_csv('train.csv', usecols=['weight', 'resp', 'ts_id', 'date'], dtype={'weight': 'float32', 'resp': 'float32'})\n",
    "    test_df = test_df[test_df['date'].isin(test_dates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[-1],y_test.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calc metric\n",
      "1231.0537292364986\n"
     ]
    }
   ],
   "source": [
    "if evalution_bool:\n",
    "    y_pred1 = np.mean(y_pred, axis=1) # n_samles x 1 (float)\n",
    "   # y_pred1 = (y_pred[:,0]*0 + y_pred[:,1]*0 + y_pred[:,2]*0 + y_pred[:,3]*0 + y_pred[:,4]*1)/1\n",
    "    y_pred_bool = np.where(y_pred1 > 0.435, 1, 0) # n_samles x 1 (int {0, 1})\n",
    "    test_df['action'] = y_pred_bool\n",
    "    test_df\n",
    "    \n",
    "    print('Calc metric')\n",
    "    Pi = []\n",
    "    for cur_date in np.unique(test_df['date']):\n",
    "        temp_df = test_df[test_df['date'] == cur_date]\n",
    "        value = sum(temp_df['weight'] * temp_df['resp'] * temp_df['action'])\n",
    "        Pi.append(value)\n",
    "    Pi = np.array(Pi)  \n",
    "    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / np.unique(test_df['date']).size)\n",
    "    u = min(max(t, 0), 6) * sum(Pi)\n",
    "    print(u)\n",
    "    neptune.log_metric('U', u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_nan_df_mean = [ 1.11248678e-02,  4.16600823e-01,  3.55446428e-01,  8.58746283e-03,\n",
    "        3.32153565e-03, -5.68061182e-03, -1.54546471e-02,  5.19358441e-02,\n",
    "        2.70631295e-02,  2.69950360e-01,  1.72372252e-01,  9.73279849e-02,\n",
    "        5.37668727e-02,  1.57676160e-01,  8.43710974e-02,  2.25111976e-01,\n",
    "        1.37447536e-01,  1.21045269e-01,  1.13533348e-01,  2.88280666e-01,\n",
    "        2.55277336e-01,  1.91205144e-01,  1.73040271e-01,  2.49782264e-01,\n",
    "        2.28465229e-01,  2.86710739e-01,  2.57286400e-01,  1.35517642e-01,\n",
    "        1.60874307e-01,  3.14388335e-01,  3.24808687e-01,  2.21792787e-01,\n",
    "        2.46316716e-01,  3.03573936e-01,  3.20882916e-01,  3.33125502e-01,\n",
    "        3.46933007e-01,  3.16174813e-02,  2.50911806e-02,  4.05390561e-02,\n",
    "        5.01634404e-02,  3.89716804e-01,  4.39725071e-01,  4.10761237e-01,\n",
    "        3.56510133e-01,  4.04844642e-01,  5.54753006e-01,  4.51396912e-01,\n",
    "        5.94792664e-01,  6.41462445e-01,  5.99166214e-01,  4.92862254e-01,\n",
    "        4.89415042e-03,  3.10924023e-01,  1.80537239e-01,  7.00669825e-01,\n",
    "        7.03996062e-01,  5.74216425e-01,  4.84798193e-01,  5.82207561e-01,\n",
    "        7.51079500e-01,  7.31717408e-01,  7.39191115e-01,  7.49898374e-01,\n",
    "        8.44931602e-01,  8.55459690e-01,  7.95409739e-01,  9.03920829e-01,\n",
    "        8.95861626e-01,  4.10086483e-01,  2.15152308e-01,  3.38279188e-01,\n",
    "        2.02515069e-03, -3.67417000e-02, -4.26720502e-03, -2.14445405e-02,\n",
    "       -3.52861769e-02, -1.12850480e-01, -9.14172083e-03, -3.85602303e-02,\n",
    "       -4.00161138e-03, -1.62717886e-02, -3.70589420e-02, -1.12429135e-01,\n",
    "        3.42513084e-01,  5.77558517e-01,  3.09788406e-01,  3.64835531e-01,\n",
    "        5.02436042e-01,  6.54584467e-01,  3.51571441e-01,  5.31417191e-01,\n",
    "        2.81628460e-01,  3.24677348e-01,  4.09467280e-01,  6.96833670e-01,\n",
    "        3.42250884e-01,  5.84956169e-01,  2.91660517e-01,  3.87508065e-01,\n",
    "        4.99385118e-01,  6.37722373e-01,  3.40197653e-01,  4.98174489e-01,\n",
    "        2.95143634e-01,  3.34093809e-01,  4.30495739e-01,  6.96529508e-01,\n",
    "        3.26292127e-01,  4.97213989e-01,  3.03535640e-01,  3.60349804e-01,\n",
    "        4.41988647e-01,  7.07466841e-01,  3.46868783e-01,  4.29639369e-01,\n",
    "        2.56859928e-01,  3.02295029e-01,  3.84930938e-01,  6.29942298e-01,\n",
    "        2.24282220e-01, -1.12973236e-01,  2.63891965e-01,  1.73168648e-02,\n",
    "        2.33980477e-01, -1.80340394e-01,  2.13665023e-01, -7.52404556e-02,\n",
    "        2.46513456e-01, -1.51326917e-02,  3.09070754e+00]\n",
    "no_nan_df_std = [0.99993837, 2.53277969, 2.43106151, 2.0240941 , 1.82004201,\n",
    "       1.75321198, 1.67698264, 1.75748312, 2.01531267, 2.32869554,\n",
    "       1.64647996, 1.54896557, 2.27313733, 2.11977959, 1.90222919,\n",
    "       1.80233765, 2.13728499, 1.71327257, 2.22850299, 1.66572917,\n",
    "       1.88361502, 2.3098278 , 1.74129856, 2.00890756, 2.4960227 ,\n",
    "       2.00843859, 2.22804308, 1.51803434, 2.07495856, 1.68902409,\n",
    "       2.03046441, 1.58326781, 2.38914442, 1.81675923, 1.95992076,\n",
    "       2.3394475 , 2.21109748, 2.12443376, 2.21838903, 1.66017544,\n",
    "       2.39466953, 1.97922707, 2.41636777, 2.33668399, 2.77381968,\n",
    "       1.90095437, 3.05546713, 2.19827724, 3.21329427, 4.04049015,\n",
    "       3.97951031, 2.8172338 , 1.87514794, 2.13836694, 1.80311501,\n",
    "       6.52135086, 9.18529034, 6.50808477, 6.7414422 , 8.16410351,\n",
    "       2.2825458 , 2.05775213, 2.23308778, 2.3178401 , 2.21779513,\n",
    "       2.19248271, 1.76868069, 2.58077908, 2.52061629, 2.26492548,\n",
    "       2.37525177, 1.79367197, 1.89814603, 2.23218226, 1.73965669,\n",
    "       1.97060454, 2.28985643, 2.80546165, 2.29513144, 1.81658137,\n",
    "       1.71284187, 2.24634171, 1.97238767, 2.59418797, 2.00102663,\n",
    "       2.58498812, 1.84393692, 2.61183286, 2.65174198, 2.65999722,\n",
    "       2.18634176, 2.72854304, 1.96498072, 2.15202546, 2.11638403,\n",
    "       2.50706887, 2.14216948, 2.6429975 , 2.15489888, 2.03357697,\n",
    "       2.29848719, 2.66446662, 2.45794606, 2.26143575, 1.74025154,\n",
    "       2.03440189, 2.76839471, 2.48702765, 2.49868393, 2.61808228,\n",
    "       1.81631255, 1.86282992, 2.61231852, 2.89367437, 2.21070409,\n",
    "       2.31932569, 2.21543431, 2.43321896, 2.36629891, 2.0953939 ,\n",
    "       1.81028557, 1.77445316, 2.0505228 , 1.79429746, 1.67098224,\n",
    "       1.86403179, 2.4819932 , 1.52141416, 2.26780057, 1.55793428,\n",
    "       7.72157001]\n",
    "features = ['weight',\n",
    " 'feature_0',\n",
    " 'feature_1',\n",
    " 'feature_2',\n",
    " 'feature_3',\n",
    " 'feature_4',\n",
    " 'feature_5',\n",
    " 'feature_6',\n",
    " 'feature_7',\n",
    " 'feature_8',\n",
    " 'feature_9',\n",
    " 'feature_10',\n",
    " 'feature_11',\n",
    " 'feature_12',\n",
    " 'feature_13',\n",
    " 'feature_14',\n",
    " 'feature_15',\n",
    " 'feature_16',\n",
    " 'feature_17',\n",
    " 'feature_18',\n",
    " 'feature_19',\n",
    " 'feature_20',\n",
    " 'feature_21',\n",
    " 'feature_22',\n",
    " 'feature_23',\n",
    " 'feature_24',\n",
    " 'feature_25',\n",
    " 'feature_26',\n",
    " 'feature_27',\n",
    " 'feature_28',\n",
    " 'feature_29',\n",
    " 'feature_30',\n",
    " 'feature_31',\n",
    " 'feature_32',\n",
    " 'feature_33',\n",
    " 'feature_34',\n",
    " 'feature_35',\n",
    " 'feature_36',\n",
    " 'feature_37',\n",
    " 'feature_38',\n",
    " 'feature_39',\n",
    " 'feature_40',\n",
    " 'feature_41',\n",
    " 'feature_42',\n",
    " 'feature_43',\n",
    " 'feature_44',\n",
    " 'feature_45',\n",
    " 'feature_46',\n",
    " 'feature_47',\n",
    " 'feature_48',\n",
    " 'feature_49',\n",
    " 'feature_50',\n",
    " 'feature_51',\n",
    " 'feature_52',\n",
    " 'feature_53',\n",
    " 'feature_54',\n",
    " 'feature_55',\n",
    " 'feature_56',\n",
    " 'feature_57',\n",
    " 'feature_58',\n",
    " 'feature_59',\n",
    " 'feature_60',\n",
    " 'feature_61',\n",
    " 'feature_62',\n",
    " 'feature_63',\n",
    " 'feature_64',\n",
    " 'feature_65',\n",
    " 'feature_66',\n",
    " 'feature_67',\n",
    " 'feature_68',\n",
    " 'feature_69',\n",
    " 'feature_70',\n",
    " 'feature_71',\n",
    " 'feature_72',\n",
    " 'feature_73',\n",
    " 'feature_74',\n",
    " 'feature_75',\n",
    " 'feature_76',\n",
    " 'feature_77',\n",
    " 'feature_78',\n",
    " 'feature_79',\n",
    " 'feature_80',\n",
    " 'feature_81',\n",
    " 'feature_82',\n",
    " 'feature_83',\n",
    " 'feature_84',\n",
    " 'feature_85',\n",
    " 'feature_86',\n",
    " 'feature_87',\n",
    " 'feature_88',\n",
    " 'feature_89',\n",
    " 'feature_90',\n",
    " 'feature_91',\n",
    " 'feature_92',\n",
    " 'feature_93',\n",
    " 'feature_94',\n",
    " 'feature_95',\n",
    " 'feature_96',\n",
    " 'feature_97',\n",
    " 'feature_98',\n",
    " 'feature_99',\n",
    " 'feature_100',\n",
    " 'feature_101',\n",
    " 'feature_102',\n",
    " 'feature_103',\n",
    " 'feature_104',\n",
    " 'feature_105',\n",
    " 'feature_106',\n",
    " 'feature_107',\n",
    " 'feature_108',\n",
    " 'feature_109',\n",
    " 'feature_110',\n",
    " 'feature_111',\n",
    " 'feature_112',\n",
    " 'feature_113',\n",
    " 'feature_114',\n",
    " 'feature_115',\n",
    " 'feature_116',\n",
    " 'feature_117',\n",
    " 'feature_118',\n",
    " 'feature_119',\n",
    " 'feature_120',\n",
    " 'feature_121',\n",
    " 'feature_122',\n",
    " 'feature_123',\n",
    " 'feature_124',\n",
    " 'feature_125',\n",
    " 'feature_126',\n",
    " 'feature_127',\n",
    " 'feature_128',\n",
    " 'feature_129',\n",
    " 'date',\n",
    " 'ts_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not train_bool:\n",
    "    import janestreet\n",
    "    env = janestreet.make_env()  \n",
    "\n",
    "    th = 0.47\n",
    "    \n",
    "    # Creating model\n",
    "    _, encoder = create_encoder(X_test.shape[-1],y_test.shape[-1],noise=0.1)\n",
    "    encoder.trainable=False\n",
    "    model = create_model(X_test.shape[-1],y_test.shape[-1],encoder)\n",
    "    model.load_weights(f'./weights/model_{SEED}.hdf5')\n",
    "    \n",
    "    \n",
    "    for (test_df, pred_df) in tqdm(env.iter_test()):     \n",
    "        \n",
    "        features = [\"feature_%d\" % i for i in range(130)] + ['weight']\n",
    "        \n",
    "        working_df = (test_df[features]-no_nan_df_mean)/no_nan_df_std\n",
    "        working_df = working_df.fillna(0)\n",
    "\n",
    "\n",
    "        y_pred = model.predict(working_df.values, verbose=1, batch_size=4096) # n_samles x 5 (float)    \n",
    "        y_pred = np.mean(y_pred, axis=1) # n_samles x 1 (float)\n",
    "        y_pred_bool = np.where(y_pred > th, 1, 0) # n_samles x 1 (int {0, 1})\n",
    "        \n",
    "        pred_df.action = y_pred_bool\n",
    "        env.predict(pred_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
